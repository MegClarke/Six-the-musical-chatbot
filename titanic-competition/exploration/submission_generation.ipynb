{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass     Sex  <7 yrs  >60 yrs\n",
      "0              1         0       3    male       0        0\n",
      "1              2         1       1  female       0        0\n",
      "2              3         1       3  female       0        0\n",
      "3              4         1       1  female       0        0\n",
      "4              5         0       3    male       0        0\n",
      "..           ...       ...     ...     ...     ...      ...\n",
      "886          887         0       2    male       0        0\n",
      "887          888         1       1  female       0        0\n",
      "888          889         0       3  female       0        0\n",
      "889          890         1       1    male       0        0\n",
      "890          891         0       3    male       0        0\n",
      "\n",
      "[891 rows x 6 columns]\n",
      "     PassengerId  Pclass     Sex  <7 yrs  >60 yrs\n",
      "0            892       3    male       0        0\n",
      "1            893       3  female       0        0\n",
      "2            894       2    male       0        1\n",
      "3            895       3    male       0        0\n",
      "4            896       3  female       0        0\n",
      "..           ...     ...     ...     ...      ...\n",
      "413         1305       3    male       0        0\n",
      "414         1306       1  female       0        0\n",
      "415         1307       3    male       0        0\n",
      "416         1308       3    male       0        0\n",
      "417         1309       3    male       0        0\n",
      "\n",
      "[418 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd    #load the data, statistics\n",
    "import seaborn as sns   #visualize the data\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder #ordinal\n",
    "from sklearn.preprocessing import OneHotEncoder #nominal, categorical\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('input/train.csv')\n",
    "#sex\n",
    "#age under 7\n",
    "#age over 60\n",
    "#pclass\n",
    "\n",
    "# Creating new categories for age\n",
    "train_df['<7 yrs'] = train_df['Age'].apply(lambda x: 1 if x < 7 else 0)\n",
    "train_df['>60 yrs'] = train_df['Age'].apply(lambda x: 1 if x > 60 else 0)\n",
    "\n",
    "selected_columns = train_df.drop(['Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'], axis=1)\n",
    "print(selected_columns)\n",
    "\n",
    "\n",
    "onehot_encoder = OneHotEncoder()\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), ['Sex', 'Pclass'])\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "\n",
    "# Define the features (X) and target (y)\n",
    "X = selected_columns[['Sex', 'Pclass', '<7 yrs', '>60 yrs']]\n",
    "y = selected_columns['Survived']\n",
    "\n",
    "#checking the preprocessor\n",
    "'''\n",
    "X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Get the feature names for the transformed data\n",
    "onehot_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(['Sex', 'Pclass'])\n",
    "all_feature_names = list(onehot_feature_names) + ['<7 yrs', '>60 yrs']\n",
    "\n",
    "# Convert the transformed data back into a DataFrame\n",
    "X_transformed_df = pd.DataFrame(X_transformed, columns=all_feature_names)\n",
    "print(X_transformed_df)\n",
    "'''\n",
    "\n",
    "#test set\n",
    "test_df = pd.read_csv('input/test.csv')\n",
    "\n",
    "test_df['<7 yrs'] = test_df['Age'].apply(lambda x: 1 if x < 7 else 0)\n",
    "test_df['>60 yrs'] = test_df['Age'].apply(lambda x: 1 if x > 60 else 0)\n",
    "\n",
    "test_df = test_df.drop(['Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'], axis=1)\n",
    "print(test_df)\n",
    "\n",
    "X_test = test_df[['Sex', 'Pclass', '<7 yrs', '>60 yrs']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0\n",
      " 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0]\n",
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         1\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         1\n",
      "..           ...       ...\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         0\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#logistic regression\n",
    "pipeline_lr = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', LogisticRegression())])\n",
    "\n",
    "pipeline_lr.fit(X, y)\n",
    "\n",
    "predictions = pipeline_lr.predict(X_test)\n",
    "print(predictions)\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "lr_submission = pd.DataFrame(test_df[['PassengerId']])\n",
    "lr_submission['Survived'] = predictions\n",
    "\n",
    "print(lr_submission)\n",
    "\n",
    "lr_submission.to_csv('output/lr_submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0\n",
      " 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 0 1 0 0 1 0 0 0]\n",
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         0\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         0\n",
      "..           ...       ...\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         0\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#decision tree\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), ['Sex', 'Pclass'])\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "# Create a pipeline that first preprocesses the data and then fits a decision tree model\n",
    "pipeline_dt = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "pipeline_dt.fit(X, y)\n",
    "\n",
    "predictions = pipeline_dt.predict(X_test)\n",
    "print(predictions)\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "dt_submission = pd.DataFrame(test_df[['PassengerId']])\n",
    "dt_submission['Survived'] = predictions\n",
    "\n",
    "print(dt_submission)\n",
    "\n",
    "dt_submission.to_csv('output/dt_submission1.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glairenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
